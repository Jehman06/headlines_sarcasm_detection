{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc553ba0-521f-4013-9fb3-036e1cfb987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "\n",
    "with open(\"Sarcasm_Headlines_Dataset.json\", 'r') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)  # Parse each line as a JSON object\n",
    "        sentences.append(item['headline'])\n",
    "        labels.append(item['is_sarcastic'])\n",
    "        urls.append(item['article_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b51855-a2cc-4dca-9282-31e9b49f2ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "(26709, 40)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences, padding='post')\n",
    "print(padded[0])\n",
    "print(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ae1107e-af49-4a0e-8218-c5247cd97de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: 21367\n",
      "Testing data shape: 5342\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data shape:\", len(X_train))\n",
    "print(\"Testing data shape:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "855eede3-1d94-4aef-8ea7-59b7b9c2ba8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (21367, 40)\n",
      "Testing data shape: (5342, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Split the data first\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizer settings\n",
    "max_length = 40  # You can adjust this\n",
    "padding_type = 'post'\n",
    "trunc_type = 'post'\n",
    "oov_token = \"<OOV>\"\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer(num_words=100000, oov_token=oov_token)\n",
    "\n",
    "# Fit the tokenizer only on the training sentences\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert training and testing sentences to sequences\n",
    "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure consistent input length\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(\"Training data shape:\", training_padded.shape)\n",
    "print(\"Testing data shape:\", testing_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae0aefe-738a-4980-897e-c5b2afeec137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "embedding_dim = 32\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = 40\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ec290e-6135-440b-a771-f0889d5a2861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 21:45:50.055194: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 - 3s - loss: 0.6606 - accuracy: 0.5940 - val_loss: 0.5621 - val_accuracy: 0.8227 - lr: 0.0010 - 3s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "668/668 - 2s - loss: 0.5245 - accuracy: 0.7560 - val_loss: 0.4592 - val_accuracy: 0.8433 - lr: 7.9433e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "668/668 - 2s - loss: 0.4622 - accuracy: 0.8175 - val_loss: 0.4250 - val_accuracy: 0.8525 - lr: 6.3096e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "668/668 - 2s - loss: 0.4237 - accuracy: 0.8425 - val_loss: 0.3995 - val_accuracy: 0.8574 - lr: 5.0119e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "668/668 - 2s - loss: 0.3907 - accuracy: 0.8571 - val_loss: 0.3877 - val_accuracy: 0.8620 - lr: 3.9811e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "668/668 - 2s - loss: 0.3704 - accuracy: 0.8673 - val_loss: 0.3812 - val_accuracy: 0.8611 - lr: 3.1623e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "668/668 - 2s - loss: 0.3564 - accuracy: 0.8696 - val_loss: 0.3777 - val_accuracy: 0.8628 - lr: 2.5119e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "668/668 - 2s - loss: 0.3486 - accuracy: 0.8776 - val_loss: 0.3745 - val_accuracy: 0.8637 - lr: 1.9953e-04 - 2s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "668/668 - 2s - loss: 0.3427 - accuracy: 0.8798 - val_loss: 0.3728 - val_accuracy: 0.8639 - lr: 1.5849e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "668/668 - 2s - loss: 0.3379 - accuracy: 0.8797 - val_loss: 0.3721 - val_accuracy: 0.8635 - lr: 1.2589e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "668/668 - 2s - loss: 0.3318 - accuracy: 0.8853 - val_loss: 0.3701 - val_accuracy: 0.8628 - lr: 1.0000e-04 - 2s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "668/668 - 2s - loss: 0.3271 - accuracy: 0.8891 - val_loss: 0.3699 - val_accuracy: 0.8633 - lr: 7.9433e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "668/668 - 2s - loss: 0.3253 - accuracy: 0.8874 - val_loss: 0.3696 - val_accuracy: 0.8635 - lr: 6.3096e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "668/668 - 2s - loss: 0.3223 - accuracy: 0.8889 - val_loss: 0.3682 - val_accuracy: 0.8626 - lr: 5.0119e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "668/668 - 2s - loss: 0.3216 - accuracy: 0.8871 - val_loss: 0.3686 - val_accuracy: 0.8626 - lr: 3.9811e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "668/668 - 2s - loss: 0.3224 - accuracy: 0.8866 - val_loss: 0.3683 - val_accuracy: 0.8626 - lr: 3.1623e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "668/668 - 2s - loss: 0.3200 - accuracy: 0.8892 - val_loss: 0.3680 - val_accuracy: 0.8630 - lr: 2.5119e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "668/668 - 2s - loss: 0.3224 - accuracy: 0.8866 - val_loss: 0.3682 - val_accuracy: 0.8632 - lr: 1.9953e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "668/668 - 2s - loss: 0.3171 - accuracy: 0.8893 - val_loss: 0.3683 - val_accuracy: 0.8641 - lr: 1.5849e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 20/30\n",
      "668/668 - 2s - loss: 0.3186 - accuracy: 0.8888 - val_loss: 0.3675 - val_accuracy: 0.8624 - lr: 1.2589e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 21/30\n",
      "668/668 - 2s - loss: 0.3173 - accuracy: 0.8895 - val_loss: 0.3677 - val_accuracy: 0.8628 - lr: 1.0000e-05 - 2s/epoch - 3ms/step\n",
      "Epoch 22/30\n",
      "668/668 - 2s - loss: 0.3175 - accuracy: 0.8886 - val_loss: 0.3680 - val_accuracy: 0.8630 - lr: 7.9433e-06 - 2s/epoch - 3ms/step\n",
      "Epoch 23/30\n",
      "668/668 - 2s - loss: 0.3181 - accuracy: 0.8903 - val_loss: 0.3678 - val_accuracy: 0.8630 - lr: 6.3096e-06 - 2s/epoch - 3ms/step\n",
      "Epoch 24/30\n",
      "668/668 - 2s - loss: 0.3177 - accuracy: 0.8878 - val_loss: 0.3676 - val_accuracy: 0.8624 - lr: 5.0119e-06 - 2s/epoch - 3ms/step\n",
      "Epoch 25/30\n",
      "668/668 - 2s - loss: 0.3169 - accuracy: 0.8890 - val_loss: 0.3678 - val_accuracy: 0.8630 - lr: 3.9811e-06 - 2s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert labels to NumPy arrays\n",
    "training_labels = np.array(y_train)\n",
    "testing_labels = np.array(y_test)\n",
    "\n",
    "num_epochs = 30\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10 ** (-(epoch / 10)))\n",
    "\n",
    "# Now fit the model\n",
    "history = model.fit(\n",
    "    training_padded, \n",
    "    training_labels, \n",
    "    epochs=num_epochs, \n",
    "    validation_data=(\n",
    "        testing_padded, \n",
    "        testing_labels\n",
    "    ), \n",
    "    verbose=2, \n",
    "    callbacks=[\n",
    "        early_stopping, \n",
    "        lr_schedule,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d22a13-4343-429a-affc-d452a0e1608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "[[0.61907405]\n",
      " [0.11660952]]\n",
      "'Bruce Springsteen Songs Ranked by the Degree of Flagrancy with Which He Uses the Word “Daddy”' is Sarcastic\n",
      "'Harris tries to turn the tables on Trump by calling him 'unhinged'' is Not Sarcastic\n"
     ]
    }
   ],
   "source": [
    "sentence = [\n",
    "    \"Bruce Springsteen Songs Ranked by the Degree of Flagrancy with Which He Uses the Word “Daddy”\",\n",
    "    \"Harris tries to turn the tables on Trump by calling him 'unhinged'\",\n",
    "]\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "sequences = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Get the predicted probabilities\n",
    "predictions = model.predict(padded)\n",
    "print(predictions)\n",
    "\n",
    "# Convert the probabilities to \"Sarcastic\" or \"Not Sarcastic\"\n",
    "threshold = 0.5\n",
    "for i, prediction in enumerate(predictions):\n",
    "    if prediction > threshold:\n",
    "        print(f\"'{sentence[i]}' is Sarcastic\")\n",
    "    else:\n",
    "        print(f\"'{sentence[i]}' is Not Sarcastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989edb8-22d9-484a-9dcf-47d160b14580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
